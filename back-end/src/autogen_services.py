import sys
import os, json
import autogen

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY is not set")

config_list = [
    {
        "model": "gpt-4o-mini",
        "api_key": openai_api_key,
    }
]

#  Agent 1 : tweet Catcher
tweet_catcher = autogen.AssistantAgent(
    name="TweetCatcher",
    system_message="You are responsible for monitoring incoming tweets and identifying those that mension the company's name. Analyze the content and sentiment of these tweets.",
    llm_config={"config_list":config_list},
)

#  Agent 2 : COntent screener
content_screener = autogen.AssistantAgent(
    name="ContentScreener",
    system_message="You role is to review tweets flagged by TweetCatcher, Assess if the content is appropriate for a response. Consider factors such as sentiment, potential controversy and relevance to the company.",
    llm_config={"config_list":config_list},
)

# Agent 3 : Reponse Generator
response_generator = autogen.AssistantAgent(
    name="ResponseGenerator",
    system_message="Based on the approved tweets generate witty and relevant reply suggestions. Ensure the responses align  and sending responses to the tweets.  Ensure that the responses align with the company's brand voice and tone.",
    llm_config={"config_list":config_list},
)

# Human Proxy for final approval
human_proxy = autogen.UserProxyAgent(
    name="HumanApproval",
    system_message="You are the final arbiter. Any responses generated by the AI must be approved by you before they are sent.",
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("APPROVE"),
    human_input_mode="ALWAYS",)


def process_tweets(tweet_content):
    tweet_catcher.initiate_chat(human_proxy, message=f'Analyze the following tweet: {tweet_content}')

    analysis = human_proxy.last_msg()["content"]

    content_screener.initiate_chat(human_proxy, message=f'Review the following tweet {tweet_content} with this analysis: {analysis}')

    screening_result = human_proxy.last_msg()["content"]

    if "appropriate" in screening_result.lower():
        response_generator.initiate_chat(human_proxy, message=f"Generate a witty reply for the following tweet: {tweet_content}")

        suggested_reply= human_proxy.last_msg()["content"]
        json.dumps({"original_tweet": tweet_content, 'analysis': analysis, "screening": screening_result, "suggested_reply": suggested_reply })
    
    return json.dumps({"original_tweet": tweet_content, 'analysis': analysis, "screening": screening_result, "suggested_reply": "None" })


if __name__=="__main__":
    tweet = sys.argv[1]
    result = process_tweets(tweet)
    print(result)
    
    